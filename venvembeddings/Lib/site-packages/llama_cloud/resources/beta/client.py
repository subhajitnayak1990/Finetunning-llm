# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.jsonable_encoder import jsonable_encoder
from ...core.remove_none_from_dict import remove_none_from_dict
from ...errors.unprocessable_entity_error import UnprocessableEntityError
from ...types.agent_data import AgentData
from ...types.batch_file_status import BatchFileStatus
from ...types.batch_item_list_response import BatchItemListResponse
from ...types.batch_job_cancel_response import BatchJobCancelResponse
from ...types.batch_job_query_response import BatchJobQueryResponse
from ...types.batch_job_response import BatchJobResponse
from ...types.batch_job_status import BatchJobStatus
from ...types.batch_job_status_response import BatchJobStatusResponse
from ...types.batch_job_type import BatchJobType
from ...types.delete_response import DeleteResponse
from ...types.directory_file_query_response import DirectoryFileQueryResponse
from ...types.directory_file_response import DirectoryFileResponse
from ...types.directory_query_response import DirectoryQueryResponse
from ...types.directory_response import DirectoryResponse
from ...types.directory_sync_job_response import DirectorySyncJobResponse
from ...types.file_filter import FileFilter
from ...types.file_query_response_v_2 import FileQueryResponseV2
from ...types.file_v_2 import FileV2
from ...types.filter_operation import FilterOperation
from ...types.http_validation_error import HttpValidationError
from ...types.item_processing_results_response import ItemProcessingResultsResponse
from ...types.llama_parse_parameters import LlamaParseParameters
from ...types.paginated_response_agent_data import PaginatedResponseAgentData
from ...types.paginated_response_aggregate_group import PaginatedResponseAggregateGroup
from ...types.paginated_response_spreadsheet_job import PaginatedResponseSpreadsheetJob
from ...types.parse_configuration import ParseConfiguration
from ...types.parse_configuration_query_response import ParseConfigurationQueryResponse
from ...types.pipeline_file_list_response import PipelineFileListResponse
from ...types.presigned_url import PresignedUrl
from ...types.split_category import SplitCategory
from ...types.split_document_input import SplitDocumentInput
from ...types.split_job_query_response import SplitJobQueryResponse
from ...types.split_job_response import SplitJobResponse
from ...types.split_strategy import SplitStrategy
from ...types.spreadsheet_job import SpreadsheetJob
from ...types.spreadsheet_parsing_config import SpreadsheetParsingConfig
from ...types.spreadsheet_result_type import SpreadsheetResultType
from ...types.usage_metric_query_response import UsageMetricQueryResponse
from .types.batch_job_create_request_job_config import BatchJobCreateRequestJobConfig
from .types.list_pipeline_files_api_v_1_beta_pipelines_pipeline_id_files_get_request_statuses_item import (
    ListPipelineFilesApiV1BetaPipelinesPipelineIdFilesGetRequestStatusesItem,
)

try:
    import pydantic
    if pydantic.__version__.startswith("1."):
        raise ImportError
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class BetaClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def create_agent_data(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        data: typing.Dict[str, typing.Any],
        deployment_name: str,
    ) -> AgentData:
        """
        Create new agent data.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str].

            - data: typing.Dict[str, typing.Any].

            - deployment_name: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_agent_data(
            data={"string": {}},
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"data": data, "deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        count: typing.Optional[bool] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        first: typing.Optional[bool] = OMIT,
        group_by: typing.Optional[typing.List[str]] = OMIT,
        offset: typing.Optional[int] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> PaginatedResponseAggregateGroup:
        """
        Aggregate agent data with grouping and optional counting/first item retrieval.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to aggregate data for

            - count: typing.Optional[bool].

            - deployment_name: str. The agent deployment's name to aggregate data for

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].

            - first: typing.Optional[bool].

            - group_by: typing.Optional[typing.List[str]].

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if count is not OMIT:
            _request["count"] = count
        if filter is not OMIT:
            _request["filter"] = filter
        if first is not OMIT:
            _request["first"] = first
        if group_by is not OMIT:
            _request["group_by"] = group_by
        if offset is not OMIT:
            _request["offset"] = offset
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:aggregate"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseAggregateGroup, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
    ) -> DeleteResponse:
        """
        Bulk delete agent data by query (deployment_name, collection, optional filters).

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to delete from

            - deployment_name: str. The agent deployment's name to delete data for

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if filter is not OMIT:
            _request["filter"] = filter
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:delete"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DeleteResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def search_agent_data_api_v_1_beta_agent_data_search_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        include_total: typing.Optional[bool] = OMIT,
        offset: typing.Optional[int] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> PaginatedResponseAgentData:
        """
        Search agent data with filtering, sorting, and pagination.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to search within

            - deployment_name: str. The agent deployment's name to search within

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].

            - include_total: typing.Optional[bool]. Whether to include the total number of items in the response

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.search_agent_data_api_v_1_beta_agent_data_search_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if filter is not OMIT:
            _request["filter"] = filter
        if include_total is not OMIT:
            _request["include_total"] = include_total
        if offset is not OMIT:
            _request["offset"] = offset
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:search"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseAgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_agent_data(
        self, item_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> AgentData:
        """
        Get agent data by ID.

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_agent_data(
            item_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_agent_data(
        self,
        item_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        data: typing.Dict[str, typing.Any],
    ) -> AgentData:
        """
        Update agent data by ID (overwrites).

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - data: typing.Dict[str, typing.Any].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.update_agent_data(
            item_id="string",
            data={"string": {}},
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder({"data": data}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_agent_data(
        self, item_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> typing.Dict[str, str]:
        """
        Delete agent data by ID.

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_agent_data(
            item_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Dict[str, str], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_batch_jobs(
        self,
        *,
        directory_id: typing.Optional[str] = None,
        job_type: typing.Optional[BatchJobType] = None,
        status: typing.Optional[BatchJobStatus] = None,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> BatchJobQueryResponse:
        """
        List all batch processing jobs for a project with optional filtering.

        Returns a paginated list of batch jobs with filters for directory, job type, and status.
        Useful for viewing job history, monitoring progress, and finding specific jobs.

        Parameters:
            - directory_id: typing.Optional[str]. Filter by directory ID

            - job_type: typing.Optional[BatchJobType]. Filter by job type (PARSE, EXTRACT, CLASSIFY)

            - status: typing.Optional[BatchJobStatus]. Filter by job status (PENDING, RUNNING, COMPLETED, FAILED, CANCELLED)

            - limit: typing.Optional[int]. Maximum number of jobs to return

            - offset: typing.Optional[int]. Number of jobs to skip for pagination

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import BatchJobStatus, BatchJobType
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_batch_jobs(
            job_type=BatchJobType.PARSE,
            status=BatchJobStatus.PENDING,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/batch-processing"),
            params=remove_none_from_dict(
                {
                    "directory_id": directory_id,
                    "job_type": job_type,
                    "status": status,
                    "limit": limit,
                    "offset": offset,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_batch_job(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        continue_as_new_threshold: typing.Optional[int] = OMIT,
        directory_id: typing.Optional[str] = OMIT,
        item_ids: typing.Optional[typing.List[str]] = OMIT,
        job_config: BatchJobCreateRequestJobConfig,
        page_size: typing.Optional[int] = OMIT,
        temporal_namespace: typing.Optional[str] = None,
    ) -> BatchJobResponse:
        """
        Create a new batch processing job for a directory.

        Processes all files in the specified directory according to the job configuration.
        The job runs asynchronously and you can monitor progress using the job status endpoint.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - continue_as_new_threshold: typing.Optional[int].

            - directory_id: typing.Optional[str].

            - item_ids: typing.Optional[typing.List[str]].

            - job_config: BatchJobCreateRequestJobConfig. Job configuration for batch processing. Can be BatchParseJobRecordCreate or ClassifyJob.

            - page_size: typing.Optional[int]. Number of files to fetch per batch from the directory (only used in directory mode)

            - temporal_namespace: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_batch_job()
        """
        _request: typing.Dict[str, typing.Any] = {"job_config": job_config}
        if continue_as_new_threshold is not OMIT:
            _request["continue_as_new_threshold"] = continue_as_new_threshold
        if directory_id is not OMIT:
            _request["directory_id"] = directory_id
        if item_ids is not OMIT:
            _request["item_ids"] = item_ids
        if page_size is not OMIT:
            _request["page_size"] = page_size
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/batch-processing"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=remove_none_from_dict(
                {**self._client_wrapper.get_headers(), "temporal-namespace": temporal_namespace}
            ),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_item_processing_results(
        self,
        item_id: str,
        *,
        job_type: typing.Optional[BatchJobType] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ItemProcessingResultsResponse:
        """
        Get all processing results for a specific item (lineage query).

        Shows complete processing history including what operations have been performed,
        with what parameters, and where outputs are stored. Useful for understanding
        what processing has already been done to avoid redundant work. Optionally filter
        by job type to see only specific processing operations.

        Parameters:
            - item_id: str.

            - job_type: typing.Optional[BatchJobType]. Filter results by job type

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import BatchJobType
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_item_processing_results(
            item_id="string",
            job_type=BatchJobType.PARSE,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/batch-processing/items/{item_id}/processing-results",
            ),
            params=remove_none_from_dict(
                {"job_type": job_type, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ItemProcessingResultsResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_batch_job_status(
        self, job_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> BatchJobStatusResponse:
        """
        Get detailed status of a batch processing job.

        Returns current progress, file counts, and estimated completion time.

        Parameters:
            - job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_batch_job_status(
            job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobStatusResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def cancel_batch_job(
        self,
        job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        reason: typing.Optional[str] = OMIT,
        temporal_namespace: typing.Optional[str] = None,
    ) -> BatchJobCancelResponse:
        """
        Cancel a running batch processing job.

        Stops processing and marks all pending items as cancelled. Items currently
        being processed may complete depending on their state.

        Parameters:
            - job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - reason: typing.Optional[str].

            - temporal_namespace: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.cancel_batch_job(
            job_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if reason is not OMIT:
            _request["reason"] = reason
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}/cancel"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=remove_none_from_dict(
                {**self._client_wrapper.get_headers(), "temporal-namespace": temporal_namespace}
            ),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobCancelResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_batch_job_items(
        self,
        job_id: str,
        *,
        status: typing.Optional[BatchFileStatus] = None,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> BatchItemListResponse:
        """
        List items in a batch job with optional status filtering.

        Useful for finding failed items, viewing completed items, or debugging issues.
        Results are paginated for performance with configurable limit and offset parameters.

        Parameters:
            - job_id: str.

            - status: typing.Optional[BatchFileStatus]. Filter items by status

            - limit: typing.Optional[int]. Maximum number of items to return

            - offset: typing.Optional[int]. Number of items to skip

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import BatchFileStatus
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_batch_job_items(
            job_id="string",
            status=BatchFileStatus.PENDING,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}/items"
            ),
            params=remove_none_from_dict(
                {
                    "status": status,
                    "limit": limit,
                    "offset": offset,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchItemListResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_directories(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        data_source_id: typing.Optional[str] = None,
        include_deleted: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> DirectoryQueryResponse:
        """
        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - name: typing.Optional[str].

            - data_source_id: typing.Optional[str].

            - include_deleted: typing.Optional[bool].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_directories()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directories"),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "name": name,
                    "data_source_id": data_source_id,
                    "include_deleted": include_deleted,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_directory(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        data_source_id: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        name: str,
    ) -> DirectoryResponse:
        """
        Create a new directory within the specified project.

        If data_source_id is provided, validates that the data source exists
        and belongs to the same project.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - data_source_id: typing.Optional[str].

            - description: typing.Optional[str].

            - name: str. Human-readable name for the directory.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_directory(
            name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"name": name}
        if data_source_id is not OMIT:
            _request["data_source_id"] = data_source_id
        if description is not OMIT:
            _request["description"] = description
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directories"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> DirectoryResponse:
        """
        Retrieve a directory by its identifier.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_directory(
            directory_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> None:
        """
        Permanently delete a directory.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_directory(
            directory_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        description: typing.Optional[str] = OMIT,
        name: typing.Optional[str] = OMIT,
    ) -> DirectoryResponse:
        """
        Update directory metadata.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - description: typing.Optional[str].

            - name: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.update_directory(
            directory_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if description is not OMIT:
            _request["description"] = description
        if name is not OMIT:
            _request["name"] = name
        _response = self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_directory_files(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = None,
        display_name_contains: typing.Optional[str] = None,
        unique_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = None,
        include_deleted: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> DirectoryFileQueryResponse:
        """
        List all files within the specified directory with optional filtering and pagination.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - display_name_contains: typing.Optional[str].

            - unique_id: typing.Optional[str].

            - file_id: typing.Optional[str].

            - include_deleted: typing.Optional[bool].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_directory_files(
            directory_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files"
            ),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "display_name": display_name,
                    "display_name_contains": display_name_contains,
                    "unique_id": unique_id,
                    "file_id": file_id,
                    "include_deleted": include_deleted,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def add_directory_file(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = OMIT,
        file_id: str,
        unique_id: typing.Optional[str] = OMIT,
    ) -> DirectoryFileResponse:
        """
        Create a new file within the specified directory.

        The directory must exist and belong to the project passed in.
        The file_id must be provided and exist in the project.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - file_id: str. File ID for the storage location (required).

            - unique_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.add_directory_file(
            directory_id="string",
            file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id}
        if display_name is not OMIT:
            _request["display_name"] = display_name
        if unique_id is not OMIT:
            _request["unique_id"] = unique_id
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def bulk_delete_directory_files(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        directory_file_ids: typing.List[str],
    ) -> None:
        """
        Delete multiple files from the specified directory.

        All files must belong to the specified directory. Maximum 100 files per request.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - directory_file_ids: typing.List[str]. List of directory file IDs to delete (max 100).
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.bulk_delete_directory_files(
            directory_id="string",
            directory_file_ids=[],
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files/bulk-delete"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder({"directory_file_ids": directory_file_ids}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upload_file_to_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = None,
        unique_id: typing.Optional[str] = None,
        upload_file: typing.IO,
    ) -> DirectoryFileResponse:
        """
        Upload a file directly to a directory.

        Uploads a file and creates a directory file entry in a single operation.
        If unique_id or display_name are not provided, they will be derived from the file metadata.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - external_file_id: typing.Optional[str].

            - unique_id: typing.Optional[str].

            - upload_file: typing.IO.
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files/upload"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            data=jsonable_encoder(
                {"display_name": display_name, "external_file_id": external_file_id, "unique_id": unique_id}
            ),
            files={"upload_file": upload_file},
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> DirectoryFileResponse:
        """
        Get a file by its directory_file_id within the specified directory. If you're trying to get a file by its unique_id, use the list endpoint with a filter instead.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> None:
        """
        Delete a file from the specified directory.

        Note: This endpoint uses directory_file_id (the internal ID). If you're trying to delete a file by its unique_id, use the list endpoint with a filter to find the directory_file_id first.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        directory_file_update_request_directory_id: typing.Optional[str] = OMIT,
        display_name: typing.Optional[str] = OMIT,
        unique_id: typing.Optional[str] = OMIT,
    ) -> DirectoryFileResponse:
        """
        Update file metadata within the specified directory.

        Supports moving files to a different directory by setting directory_id.

        Note: This endpoint uses directory_file_id (the internal ID). If you're trying to update a file by its unique_id, use the list endpoint with a filter to find the directory_file_id first.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - directory_file_update_request_directory_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - unique_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.update_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if directory_file_update_request_directory_id is not OMIT:
            _request["directory_id"] = directory_file_update_request_directory_id
        if display_name is not OMIT:
            _request["display_name"] = display_name
        if unique_id is not OMIT:
            _request["unique_id"] = unique_id
        _response = self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_directory_sync_job_api_v_1_beta_directory_sync_jobs_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        directory_id: str,
    ) -> DirectorySyncJobResponse:
        """
        Create a new directory sync job.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - directory_id: str. Directory being processed
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_directory_sync_job_api_v_1_beta_directory_sync_jobs_post(
            directory_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directory-sync-jobs"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder({"directory_id": directory_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectorySyncJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_directory_sync_job(
        self, job_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> DirectorySyncJobResponse:
        """
        Get a directory sync job by ID.

        Parameters:
            - job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_directory_sync_job(
            job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directory-sync-jobs/{job_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectorySyncJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_files(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        file_ids: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        file_name: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = None,
        order_by: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> FileQueryResponseV2:
        """
        List files with optional filtering and pagination.

        This endpoint retrieves files for the specified project with support for
        filtering by various criteria and cursor-based pagination.

        Parameters:
            - page_size: typing.Optional[int]. The maximum number of items to return. Defaults to 50, maximum is 1000.

            - page_token: typing.Optional[str]. A page token received from a previous list call. Provide this to retrieve the subsequent page.

            - file_ids: typing.Optional[typing.Union[str, typing.List[str]]]. Filter by specific file IDs.

            - file_name: typing.Optional[str]. Filter by file name (exact match).

            - external_file_id: typing.Optional[str]. Filter by external file ID.

            - order_by: typing.Optional[str]. A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_files()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "file_ids": file_ids,
                    "file_name": file_name,
                    "external_file_id": external_file_id,
                    "order_by": order_by,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileQueryResponseV2, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upload_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = None,
        file: typing.IO,
        purpose: str,
    ) -> FileV2:
        """
        Upload a file using multipart/form-data.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - external_file_id: typing.Optional[str].

            - file: typing.IO.

            - purpose: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            data=jsonable_encoder({"external_file_id": external_file_id, "purpose": purpose}),
            files={"file": file},
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileV2, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def query_files(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        filter: typing.Optional[FileFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> FileQueryResponseV2:
        """
        Query files with flexible filtering and pagination.

        **Deprecated**: Use GET /files instead for listing files with query parameters.

        Args:
        request: The query request with filters and pagination
        project: Validated project from dependency
        db: Database session

        Returns:
        Paginated response with files

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - filter: typing.Optional[FileFilter].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud import FileFilter
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.query_files(
            filter=FileFilter(),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if filter is not OMIT:
            _request["filter"] = filter
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files/query"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileQueryResponseV2, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_file(
        self, file_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> None:
        """
        Delete a single file from the project.

        Args:
        file_id: The ID of the file to delete
        project: Validated project from dependency
        db: Database session

        Returns:
        None (204 No Content on success)

        Parameters:
            - file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_file(
            file_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/files/{file_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def read_file_content(
        self,
        file_id: str,
        *,
        expires_at_seconds: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> PresignedUrl:
        """
        Returns a presigned url to read the file content.

        Parameters:
            - file_id: str.

            - expires_at_seconds: typing.Optional[int].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.read_file_content(
            file_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/files/{file_id}/content"),
            params=remove_none_from_dict(
                {"expires_at_seconds": expires_at_seconds, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_parse_configurations(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        creator: typing.Optional[str] = None,
        version: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ParseConfigurationQueryResponse:
        """
        List parse configurations for the current project.

        Args:
        project: Validated project from dependency
        user: Current user
        db: Database session
        page_size: Number of items per page
        page_token: Token for pagination
        name: Filter by configuration name
        creator: Filter by creator
        version: Filter by version

        Returns:
        Paginated response with parse configurations

        Parameters:
            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].

            - name: typing.Optional[str].

            - creator: typing.Optional[str].

            - version: typing.Optional[str].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_parse_configurations()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "name": name,
                    "creator": creator,
                    "version": version,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfigurationQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_parse_configuration(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        creator: typing.Optional[str] = OMIT,
        name: str,
        parameters: LlamaParseParameters,
        source_id: typing.Optional[str] = OMIT,
        source_type: typing.Optional[str] = OMIT,
        version: str,
    ) -> ParseConfiguration:
        """
        Create a new parse configuration.

        Args:
        config_create: Parse configuration creation data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The created parse configuration

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - creator: typing.Optional[str].

            - name: str. Name of the parse configuration

            - parameters: LlamaParseParameters. LlamaParseParameters configuration

            - source_id: typing.Optional[str].

            - source_type: typing.Optional[str].

            - version: str. Version of the configuration
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParsingMode,
        )
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_parse_configuration(
            name="string",
            parameters=LlamaParseParameters(
                parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                priority=LlamaParseParametersPriority.LOW,
                replace_failed_page_mode=FailPageMode.RAW_TEXT,
            ),
            version="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"name": name, "parameters": parameters, "version": version}
        if creator is not OMIT:
            _request["creator"] = creator
        if source_id is not OMIT:
            _request["source_id"] = source_id
        if source_type is not OMIT:
            _request["source_type"] = source_type
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_parse_configuration(
        self, config_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> ParseConfiguration:
        """
        Get a parse configuration by ID.

        Args:
        config_id: The ID of the parse configuration
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The parse configuration

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_parse_configuration(
            config_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        parameters: typing.Optional[LlamaParseParameters] = OMIT,
    ) -> ParseConfiguration:
        """
        Update a parse configuration.

        Args:
        config_id: The ID of the parse configuration to update
        config_update: Update data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The updated parse configuration

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - parameters: typing.Optional[LlamaParseParameters].
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParsingMode,
        )
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.update_parse_configuration(
            config_id="string",
            parameters=LlamaParseParameters(
                parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                priority=LlamaParseParametersPriority.LOW,
                replace_failed_page_mode=FailPageMode.RAW_TEXT,
            ),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if parameters is not OMIT:
            _request["parameters"] = parameters
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_parse_configuration(
        self, config_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> None:
        """
        Delete a parse configuration.

        Args:
        config_id: The ID of the parse configuration to delete
        project: Validated project from dependency
        user: Current user
        db: Database session

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_parse_configuration(
            config_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_pipeline_files(
        self,
        pipeline_id: str,
        *,
        data_source_id: typing.Optional[str] = None,
        file_name_contains: typing.Optional[str] = None,
        statuses: typing.Optional[
            typing.Union[
                ListPipelineFilesApiV1BetaPipelinesPipelineIdFilesGetRequestStatusesItem,
                typing.List[ListPipelineFilesApiV1BetaPipelinesPipelineIdFilesGetRequestStatusesItem],
            ]
        ] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> PipelineFileListResponse:
        """
        List files for a pipeline with pagination and filtering.

        Parameters:
            - pipeline_id: str.

            - data_source_id: typing.Optional[str]. Filter by data source ID.

            - file_name_contains: typing.Optional[str]. Filter by files whose names contain this substring (case-insensitive).

            - statuses: typing.Optional[typing.Union[ListPipelineFilesApiV1BetaPipelinesPipelineIdFilesGetRequestStatusesItem, typing.List[ListPipelineFilesApiV1BetaPipelinesPipelineIdFilesGetRequestStatusesItem]]]. Filter by pipeline file statuses.

            - page_size: typing.Optional[int]. Maximum number of items to return. Defaults to 50, max 1000.

            - page_token: typing.Optional[str]. Page token for pagination, from a previous response.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_pipeline_files(
            pipeline_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/pipelines/{pipeline_id}/files"
            ),
            params=remove_none_from_dict(
                {
                    "data_source_id": data_source_id,
                    "file_name_contains": file_name_contains,
                    "statuses": statuses,
                    "page_size": page_size,
                    "page_token": page_token,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PipelineFileListResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_spreadsheet_jobs(
        self,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> PaginatedResponseSpreadsheetJob:
        """
        List spreadsheet parsing jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - include_results: typing.Optional[bool].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_spreadsheet_jobs()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/sheets/jobs"),
            params=remove_none_from_dict(
                {
                    "include_results": include_results,
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseSpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_spreadsheet_job(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        config: typing.Optional[SpreadsheetParsingConfig] = OMIT,
        file_id: str,
    ) -> SpreadsheetJob:
        """
        Create a spreadsheet parsing job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - config: typing.Optional[SpreadsheetParsingConfig]. Configuration for the parsing job

            - file_id: str. The ID of the file to parse
        ---
        from llama_cloud import (
            SpreadsheetParsingConfig,
            SpreadsheetParsingConfigTableMergeSensitivity,
        )
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_spreadsheet_job(
            config=SpreadsheetParsingConfig(
                table_merge_sensitivity=SpreadsheetParsingConfigTableMergeSensitivity.STRONG,
            ),
            file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id}
        if config is not OMIT:
            _request["config"] = config
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/sheets/jobs"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_spreadsheet_job(
        self,
        spreadsheet_job_id: str,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> SpreadsheetJob:
        """
        Get a spreadsheet parsing job.

        When include_results=True (default), the response will include extracted regions and results
        if the job is complete, eliminating the need for a separate /results call.

        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - include_results: typing.Optional[bool].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_spreadsheet_job(
            spreadsheet_job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/sheets/jobs/{spreadsheet_job_id}"
            ),
            params=remove_none_from_dict(
                {"include_results": include_results, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_spreadsheet_job(
        self,
        spreadsheet_job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> typing.Any:
        """
        Delete a spreadsheet parsing job and its associated data.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_spreadsheet_job(
            spreadsheet_job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/sheets/jobs/{spreadsheet_job_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_result_region(
        self,
        spreadsheet_job_id: str,
        region_id: str,
        region_type: SpreadsheetResultType,
        *,
        expires_at_seconds: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> PresignedUrl:
        """
        Generate a presigned URL to download a specific extracted region.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - region_id: str.

            - region_type: SpreadsheetResultType.

            - expires_at_seconds: typing.Optional[int].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import SpreadsheetResultType
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_result_region(
            spreadsheet_job_id="string",
            region_id="string",
            region_type=SpreadsheetResultType.TABLE,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/sheets/jobs/{spreadsheet_job_id}/regions/{region_id}/result/{region_type}",
            ),
            params=remove_none_from_dict(
                {"expires_at_seconds": expires_at_seconds, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_split_jobs(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> SplitJobQueryResponse:
        """
        List document split jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_split_jobs()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/split/jobs"),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SplitJobQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_split_job(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        categories: typing.List[SplitCategory],
        document_input: SplitDocumentInput,
        splitting_strategy: typing.Optional[SplitStrategy] = OMIT,
    ) -> SplitJobResponse:
        """
        Create a document split job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - categories: typing.List[SplitCategory]. Categories to split the document into.

            - document_input: SplitDocumentInput. Document to be split.

            - splitting_strategy: typing.Optional[SplitStrategy]. Strategy for splitting the document.
        ---
        from llama_cloud import SplitDocumentInput, SplitStrategy
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_split_job(
            categories=[],
            document_input=SplitDocumentInput(
                type="string",
                value="string",
            ),
            splitting_strategy=SplitStrategy(),
        )
        """
        _request: typing.Dict[str, typing.Any] = {"categories": categories, "document_input": document_input}
        if splitting_strategy is not OMIT:
            _request["splitting_strategy"] = splitting_strategy
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/split/jobs"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SplitJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_split_job(
        self,
        split_job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> SplitJobResponse:
        """
        Get a document split job.

        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - split_job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_split_job(
            split_job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/split/jobs/{split_job_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SplitJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_usage_metrics(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        include_total: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        user_id: typing.Optional[str] = None,
        event_types: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        days: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        day_on_or_before: typing.Optional[str] = None,
        day_on_or_after: typing.Optional[str] = None,
        event_aggregation_type: typing.Optional[str] = None,
        event_aggregation_key: typing.Optional[str] = None,
        organization_id: str,
    ) -> UsageMetricQueryResponse:
        """
        List usage metrics with filtering and pagination.

        Parameters:
            - page_size: typing.Optional[int]. Number of items per page

            - page_token: typing.Optional[str]. Token for pagination

            - include_total: typing.Optional[bool]. Include total count in response

            - project_id: typing.Optional[str]. Filter by project ID

            - user_id: typing.Optional[str]. Filter by user ID

            - event_types: typing.Optional[typing.Union[str, typing.List[str]]]. Filter by event types

            - days: typing.Optional[typing.Union[str, typing.List[str]]]. Filter by specific days (YYYY-MM-DD)

            - day_on_or_before: typing.Optional[str]. Filter by days on or before this date (YYYY-MM-DD)

            - day_on_or_after: typing.Optional[str]. Filter by days on or after this date (YYYY-MM-DD)

            - event_aggregation_type: typing.Optional[str]. Filter by event aggregation type

            - event_aggregation_key: typing.Optional[str]. Filter by event aggregation key

            - organization_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_usage_metrics(
            organization_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/usage-metrics"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "include_total": include_total,
                    "project_id": project_id,
                    "user_id": user_id,
                    "event_types": event_types,
                    "days": days,
                    "day_on_or_before": day_on_or_before,
                    "day_on_or_after": day_on_or_after,
                    "event_aggregation_type": event_aggregation_type,
                    "event_aggregation_key": event_aggregation_key,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UsageMetricQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncBetaClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def create_agent_data(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        data: typing.Dict[str, typing.Any],
        deployment_name: str,
    ) -> AgentData:
        """
        Create new agent data.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str].

            - data: typing.Dict[str, typing.Any].

            - deployment_name: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_agent_data(
            data={"string": {}},
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"data": data, "deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        count: typing.Optional[bool] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        first: typing.Optional[bool] = OMIT,
        group_by: typing.Optional[typing.List[str]] = OMIT,
        offset: typing.Optional[int] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> PaginatedResponseAggregateGroup:
        """
        Aggregate agent data with grouping and optional counting/first item retrieval.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to aggregate data for

            - count: typing.Optional[bool].

            - deployment_name: str. The agent deployment's name to aggregate data for

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].

            - first: typing.Optional[bool].

            - group_by: typing.Optional[typing.List[str]].

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if count is not OMIT:
            _request["count"] = count
        if filter is not OMIT:
            _request["filter"] = filter
        if first is not OMIT:
            _request["first"] = first
        if group_by is not OMIT:
            _request["group_by"] = group_by
        if offset is not OMIT:
            _request["offset"] = offset
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:aggregate"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseAggregateGroup, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
    ) -> DeleteResponse:
        """
        Bulk delete agent data by query (deployment_name, collection, optional filters).

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to delete from

            - deployment_name: str. The agent deployment's name to delete data for

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if filter is not OMIT:
            _request["filter"] = filter
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:delete"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DeleteResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def search_agent_data_api_v_1_beta_agent_data_search_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        include_total: typing.Optional[bool] = OMIT,
        offset: typing.Optional[int] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> PaginatedResponseAgentData:
        """
        Search agent data with filtering, sorting, and pagination.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to search within

            - deployment_name: str. The agent deployment's name to search within

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].

            - include_total: typing.Optional[bool]. Whether to include the total number of items in the response

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.search_agent_data_api_v_1_beta_agent_data_search_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if filter is not OMIT:
            _request["filter"] = filter
        if include_total is not OMIT:
            _request["include_total"] = include_total
        if offset is not OMIT:
            _request["offset"] = offset
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:search"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseAgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_agent_data(
        self, item_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> AgentData:
        """
        Get agent data by ID.

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_agent_data(
            item_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_agent_data(
        self,
        item_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        data: typing.Dict[str, typing.Any],
    ) -> AgentData:
        """
        Update agent data by ID (overwrites).

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - data: typing.Dict[str, typing.Any].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.update_agent_data(
            item_id="string",
            data={"string": {}},
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder({"data": data}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_agent_data(
        self, item_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> typing.Dict[str, str]:
        """
        Delete agent data by ID.

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_agent_data(
            item_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Dict[str, str], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_batch_jobs(
        self,
        *,
        directory_id: typing.Optional[str] = None,
        job_type: typing.Optional[BatchJobType] = None,
        status: typing.Optional[BatchJobStatus] = None,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> BatchJobQueryResponse:
        """
        List all batch processing jobs for a project with optional filtering.

        Returns a paginated list of batch jobs with filters for directory, job type, and status.
        Useful for viewing job history, monitoring progress, and finding specific jobs.

        Parameters:
            - directory_id: typing.Optional[str]. Filter by directory ID

            - job_type: typing.Optional[BatchJobType]. Filter by job type (PARSE, EXTRACT, CLASSIFY)

            - status: typing.Optional[BatchJobStatus]. Filter by job status (PENDING, RUNNING, COMPLETED, FAILED, CANCELLED)

            - limit: typing.Optional[int]. Maximum number of jobs to return

            - offset: typing.Optional[int]. Number of jobs to skip for pagination

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import BatchJobStatus, BatchJobType
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_batch_jobs(
            job_type=BatchJobType.PARSE,
            status=BatchJobStatus.PENDING,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/batch-processing"),
            params=remove_none_from_dict(
                {
                    "directory_id": directory_id,
                    "job_type": job_type,
                    "status": status,
                    "limit": limit,
                    "offset": offset,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_batch_job(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        continue_as_new_threshold: typing.Optional[int] = OMIT,
        directory_id: typing.Optional[str] = OMIT,
        item_ids: typing.Optional[typing.List[str]] = OMIT,
        job_config: BatchJobCreateRequestJobConfig,
        page_size: typing.Optional[int] = OMIT,
        temporal_namespace: typing.Optional[str] = None,
    ) -> BatchJobResponse:
        """
        Create a new batch processing job for a directory.

        Processes all files in the specified directory according to the job configuration.
        The job runs asynchronously and you can monitor progress using the job status endpoint.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - continue_as_new_threshold: typing.Optional[int].

            - directory_id: typing.Optional[str].

            - item_ids: typing.Optional[typing.List[str]].

            - job_config: BatchJobCreateRequestJobConfig. Job configuration for batch processing. Can be BatchParseJobRecordCreate or ClassifyJob.

            - page_size: typing.Optional[int]. Number of files to fetch per batch from the directory (only used in directory mode)

            - temporal_namespace: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_batch_job()
        """
        _request: typing.Dict[str, typing.Any] = {"job_config": job_config}
        if continue_as_new_threshold is not OMIT:
            _request["continue_as_new_threshold"] = continue_as_new_threshold
        if directory_id is not OMIT:
            _request["directory_id"] = directory_id
        if item_ids is not OMIT:
            _request["item_ids"] = item_ids
        if page_size is not OMIT:
            _request["page_size"] = page_size
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/batch-processing"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=remove_none_from_dict(
                {**self._client_wrapper.get_headers(), "temporal-namespace": temporal_namespace}
            ),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_item_processing_results(
        self,
        item_id: str,
        *,
        job_type: typing.Optional[BatchJobType] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ItemProcessingResultsResponse:
        """
        Get all processing results for a specific item (lineage query).

        Shows complete processing history including what operations have been performed,
        with what parameters, and where outputs are stored. Useful for understanding
        what processing has already been done to avoid redundant work. Optionally filter
        by job type to see only specific processing operations.

        Parameters:
            - item_id: str.

            - job_type: typing.Optional[BatchJobType]. Filter results by job type

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import BatchJobType
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_item_processing_results(
            item_id="string",
            job_type=BatchJobType.PARSE,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/batch-processing/items/{item_id}/processing-results",
            ),
            params=remove_none_from_dict(
                {"job_type": job_type, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ItemProcessingResultsResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_batch_job_status(
        self, job_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> BatchJobStatusResponse:
        """
        Get detailed status of a batch processing job.

        Returns current progress, file counts, and estimated completion time.

        Parameters:
            - job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_batch_job_status(
            job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobStatusResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def cancel_batch_job(
        self,
        job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        reason: typing.Optional[str] = OMIT,
        temporal_namespace: typing.Optional[str] = None,
    ) -> BatchJobCancelResponse:
        """
        Cancel a running batch processing job.

        Stops processing and marks all pending items as cancelled. Items currently
        being processed may complete depending on their state.

        Parameters:
            - job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - reason: typing.Optional[str].

            - temporal_namespace: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.cancel_batch_job(
            job_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if reason is not OMIT:
            _request["reason"] = reason
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}/cancel"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=remove_none_from_dict(
                {**self._client_wrapper.get_headers(), "temporal-namespace": temporal_namespace}
            ),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobCancelResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_batch_job_items(
        self,
        job_id: str,
        *,
        status: typing.Optional[BatchFileStatus] = None,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> BatchItemListResponse:
        """
        List items in a batch job with optional status filtering.

        Useful for finding failed items, viewing completed items, or debugging issues.
        Results are paginated for performance with configurable limit and offset parameters.

        Parameters:
            - job_id: str.

            - status: typing.Optional[BatchFileStatus]. Filter items by status

            - limit: typing.Optional[int]. Maximum number of items to return

            - offset: typing.Optional[int]. Number of items to skip

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import BatchFileStatus
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_batch_job_items(
            job_id="string",
            status=BatchFileStatus.PENDING,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}/items"
            ),
            params=remove_none_from_dict(
                {
                    "status": status,
                    "limit": limit,
                    "offset": offset,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchItemListResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_directories(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        data_source_id: typing.Optional[str] = None,
        include_deleted: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> DirectoryQueryResponse:
        """
        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - name: typing.Optional[str].

            - data_source_id: typing.Optional[str].

            - include_deleted: typing.Optional[bool].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_directories()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directories"),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "name": name,
                    "data_source_id": data_source_id,
                    "include_deleted": include_deleted,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_directory(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        data_source_id: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        name: str,
    ) -> DirectoryResponse:
        """
        Create a new directory within the specified project.

        If data_source_id is provided, validates that the data source exists
        and belongs to the same project.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - data_source_id: typing.Optional[str].

            - description: typing.Optional[str].

            - name: str. Human-readable name for the directory.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_directory(
            name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"name": name}
        if data_source_id is not OMIT:
            _request["data_source_id"] = data_source_id
        if description is not OMIT:
            _request["description"] = description
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directories"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> DirectoryResponse:
        """
        Retrieve a directory by its identifier.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_directory(
            directory_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> None:
        """
        Permanently delete a directory.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_directory(
            directory_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        description: typing.Optional[str] = OMIT,
        name: typing.Optional[str] = OMIT,
    ) -> DirectoryResponse:
        """
        Update directory metadata.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - description: typing.Optional[str].

            - name: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.update_directory(
            directory_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if description is not OMIT:
            _request["description"] = description
        if name is not OMIT:
            _request["name"] = name
        _response = await self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_directory_files(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = None,
        display_name_contains: typing.Optional[str] = None,
        unique_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = None,
        include_deleted: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> DirectoryFileQueryResponse:
        """
        List all files within the specified directory with optional filtering and pagination.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - display_name_contains: typing.Optional[str].

            - unique_id: typing.Optional[str].

            - file_id: typing.Optional[str].

            - include_deleted: typing.Optional[bool].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_directory_files(
            directory_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files"
            ),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "display_name": display_name,
                    "display_name_contains": display_name_contains,
                    "unique_id": unique_id,
                    "file_id": file_id,
                    "include_deleted": include_deleted,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def add_directory_file(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = OMIT,
        file_id: str,
        unique_id: typing.Optional[str] = OMIT,
    ) -> DirectoryFileResponse:
        """
        Create a new file within the specified directory.

        The directory must exist and belong to the project passed in.
        The file_id must be provided and exist in the project.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - file_id: str. File ID for the storage location (required).

            - unique_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.add_directory_file(
            directory_id="string",
            file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id}
        if display_name is not OMIT:
            _request["display_name"] = display_name
        if unique_id is not OMIT:
            _request["unique_id"] = unique_id
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def bulk_delete_directory_files(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        directory_file_ids: typing.List[str],
    ) -> None:
        """
        Delete multiple files from the specified directory.

        All files must belong to the specified directory. Maximum 100 files per request.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - directory_file_ids: typing.List[str]. List of directory file IDs to delete (max 100).
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.bulk_delete_directory_files(
            directory_id="string",
            directory_file_ids=[],
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files/bulk-delete"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder({"directory_file_ids": directory_file_ids}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upload_file_to_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = None,
        unique_id: typing.Optional[str] = None,
        upload_file: typing.IO,
    ) -> DirectoryFileResponse:
        """
        Upload a file directly to a directory.

        Uploads a file and creates a directory file entry in a single operation.
        If unique_id or display_name are not provided, they will be derived from the file metadata.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - external_file_id: typing.Optional[str].

            - unique_id: typing.Optional[str].

            - upload_file: typing.IO.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files/upload"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            data=jsonable_encoder(
                {"display_name": display_name, "external_file_id": external_file_id, "unique_id": unique_id}
            ),
            files={"upload_file": upload_file},
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> DirectoryFileResponse:
        """
        Get a file by its directory_file_id within the specified directory. If you're trying to get a file by its unique_id, use the list endpoint with a filter instead.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> None:
        """
        Delete a file from the specified directory.

        Note: This endpoint uses directory_file_id (the internal ID). If you're trying to delete a file by its unique_id, use the list endpoint with a filter to find the directory_file_id first.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        directory_file_update_request_directory_id: typing.Optional[str] = OMIT,
        display_name: typing.Optional[str] = OMIT,
        unique_id: typing.Optional[str] = OMIT,
    ) -> DirectoryFileResponse:
        """
        Update file metadata within the specified directory.

        Supports moving files to a different directory by setting directory_id.

        Note: This endpoint uses directory_file_id (the internal ID). If you're trying to update a file by its unique_id, use the list endpoint with a filter to find the directory_file_id first.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - directory_file_update_request_directory_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - unique_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.update_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if directory_file_update_request_directory_id is not OMIT:
            _request["directory_id"] = directory_file_update_request_directory_id
        if display_name is not OMIT:
            _request["display_name"] = display_name
        if unique_id is not OMIT:
            _request["unique_id"] = unique_id
        _response = await self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_directory_sync_job_api_v_1_beta_directory_sync_jobs_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        directory_id: str,
    ) -> DirectorySyncJobResponse:
        """
        Create a new directory sync job.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - directory_id: str. Directory being processed
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_directory_sync_job_api_v_1_beta_directory_sync_jobs_post(
            directory_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directory-sync-jobs"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder({"directory_id": directory_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectorySyncJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_directory_sync_job(
        self, job_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> DirectorySyncJobResponse:
        """
        Get a directory sync job by ID.

        Parameters:
            - job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_directory_sync_job(
            job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directory-sync-jobs/{job_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectorySyncJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_files(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        file_ids: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        file_name: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = None,
        order_by: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> FileQueryResponseV2:
        """
        List files with optional filtering and pagination.

        This endpoint retrieves files for the specified project with support for
        filtering by various criteria and cursor-based pagination.

        Parameters:
            - page_size: typing.Optional[int]. The maximum number of items to return. Defaults to 50, maximum is 1000.

            - page_token: typing.Optional[str]. A page token received from a previous list call. Provide this to retrieve the subsequent page.

            - file_ids: typing.Optional[typing.Union[str, typing.List[str]]]. Filter by specific file IDs.

            - file_name: typing.Optional[str]. Filter by file name (exact match).

            - external_file_id: typing.Optional[str]. Filter by external file ID.

            - order_by: typing.Optional[str]. A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_files()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "file_ids": file_ids,
                    "file_name": file_name,
                    "external_file_id": external_file_id,
                    "order_by": order_by,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileQueryResponseV2, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upload_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = None,
        file: typing.IO,
        purpose: str,
    ) -> FileV2:
        """
        Upload a file using multipart/form-data.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - external_file_id: typing.Optional[str].

            - file: typing.IO.

            - purpose: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            data=jsonable_encoder({"external_file_id": external_file_id, "purpose": purpose}),
            files={"file": file},
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileV2, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def query_files(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        filter: typing.Optional[FileFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> FileQueryResponseV2:
        """
        Query files with flexible filtering and pagination.

        **Deprecated**: Use GET /files instead for listing files with query parameters.

        Args:
        request: The query request with filters and pagination
        project: Validated project from dependency
        db: Database session

        Returns:
        Paginated response with files

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - filter: typing.Optional[FileFilter].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud import FileFilter
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.query_files(
            filter=FileFilter(),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if filter is not OMIT:
            _request["filter"] = filter
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files/query"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileQueryResponseV2, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_file(
        self, file_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> None:
        """
        Delete a single file from the project.

        Args:
        file_id: The ID of the file to delete
        project: Validated project from dependency
        db: Database session

        Returns:
        None (204 No Content on success)

        Parameters:
            - file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_file(
            file_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/files/{file_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def read_file_content(
        self,
        file_id: str,
        *,
        expires_at_seconds: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> PresignedUrl:
        """
        Returns a presigned url to read the file content.

        Parameters:
            - file_id: str.

            - expires_at_seconds: typing.Optional[int].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.read_file_content(
            file_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/files/{file_id}/content"),
            params=remove_none_from_dict(
                {"expires_at_seconds": expires_at_seconds, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_parse_configurations(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        creator: typing.Optional[str] = None,
        version: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ParseConfigurationQueryResponse:
        """
        List parse configurations for the current project.

        Args:
        project: Validated project from dependency
        user: Current user
        db: Database session
        page_size: Number of items per page
        page_token: Token for pagination
        name: Filter by configuration name
        creator: Filter by creator
        version: Filter by version

        Returns:
        Paginated response with parse configurations

        Parameters:
            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].

            - name: typing.Optional[str].

            - creator: typing.Optional[str].

            - version: typing.Optional[str].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_parse_configurations()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "name": name,
                    "creator": creator,
                    "version": version,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfigurationQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_parse_configuration(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        creator: typing.Optional[str] = OMIT,
        name: str,
        parameters: LlamaParseParameters,
        source_id: typing.Optional[str] = OMIT,
        source_type: typing.Optional[str] = OMIT,
        version: str,
    ) -> ParseConfiguration:
        """
        Create a new parse configuration.

        Args:
        config_create: Parse configuration creation data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The created parse configuration

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - creator: typing.Optional[str].

            - name: str. Name of the parse configuration

            - parameters: LlamaParseParameters. LlamaParseParameters configuration

            - source_id: typing.Optional[str].

            - source_type: typing.Optional[str].

            - version: str. Version of the configuration
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParsingMode,
        )
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_parse_configuration(
            name="string",
            parameters=LlamaParseParameters(
                parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                priority=LlamaParseParametersPriority.LOW,
                replace_failed_page_mode=FailPageMode.RAW_TEXT,
            ),
            version="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"name": name, "parameters": parameters, "version": version}
        if creator is not OMIT:
            _request["creator"] = creator
        if source_id is not OMIT:
            _request["source_id"] = source_id
        if source_type is not OMIT:
            _request["source_type"] = source_type
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_parse_configuration(
        self, config_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> ParseConfiguration:
        """
        Get a parse configuration by ID.

        Args:
        config_id: The ID of the parse configuration
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The parse configuration

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_parse_configuration(
            config_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        parameters: typing.Optional[LlamaParseParameters] = OMIT,
    ) -> ParseConfiguration:
        """
        Update a parse configuration.

        Args:
        config_id: The ID of the parse configuration to update
        config_update: Update data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The updated parse configuration

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - parameters: typing.Optional[LlamaParseParameters].
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParsingMode,
        )
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.update_parse_configuration(
            config_id="string",
            parameters=LlamaParseParameters(
                parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                priority=LlamaParseParametersPriority.LOW,
                replace_failed_page_mode=FailPageMode.RAW_TEXT,
            ),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if parameters is not OMIT:
            _request["parameters"] = parameters
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_parse_configuration(
        self, config_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> None:
        """
        Delete a parse configuration.

        Args:
        config_id: The ID of the parse configuration to delete
        project: Validated project from dependency
        user: Current user
        db: Database session

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_parse_configuration(
            config_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_pipeline_files(
        self,
        pipeline_id: str,
        *,
        data_source_id: typing.Optional[str] = None,
        file_name_contains: typing.Optional[str] = None,
        statuses: typing.Optional[
            typing.Union[
                ListPipelineFilesApiV1BetaPipelinesPipelineIdFilesGetRequestStatusesItem,
                typing.List[ListPipelineFilesApiV1BetaPipelinesPipelineIdFilesGetRequestStatusesItem],
            ]
        ] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> PipelineFileListResponse:
        """
        List files for a pipeline with pagination and filtering.

        Parameters:
            - pipeline_id: str.

            - data_source_id: typing.Optional[str]. Filter by data source ID.

            - file_name_contains: typing.Optional[str]. Filter by files whose names contain this substring (case-insensitive).

            - statuses: typing.Optional[typing.Union[ListPipelineFilesApiV1BetaPipelinesPipelineIdFilesGetRequestStatusesItem, typing.List[ListPipelineFilesApiV1BetaPipelinesPipelineIdFilesGetRequestStatusesItem]]]. Filter by pipeline file statuses.

            - page_size: typing.Optional[int]. Maximum number of items to return. Defaults to 50, max 1000.

            - page_token: typing.Optional[str]. Page token for pagination, from a previous response.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_pipeline_files(
            pipeline_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/pipelines/{pipeline_id}/files"
            ),
            params=remove_none_from_dict(
                {
                    "data_source_id": data_source_id,
                    "file_name_contains": file_name_contains,
                    "statuses": statuses,
                    "page_size": page_size,
                    "page_token": page_token,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PipelineFileListResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_spreadsheet_jobs(
        self,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> PaginatedResponseSpreadsheetJob:
        """
        List spreadsheet parsing jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - include_results: typing.Optional[bool].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_spreadsheet_jobs()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/sheets/jobs"),
            params=remove_none_from_dict(
                {
                    "include_results": include_results,
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseSpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_spreadsheet_job(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        config: typing.Optional[SpreadsheetParsingConfig] = OMIT,
        file_id: str,
    ) -> SpreadsheetJob:
        """
        Create a spreadsheet parsing job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - config: typing.Optional[SpreadsheetParsingConfig]. Configuration for the parsing job

            - file_id: str. The ID of the file to parse
        ---
        from llama_cloud import (
            SpreadsheetParsingConfig,
            SpreadsheetParsingConfigTableMergeSensitivity,
        )
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_spreadsheet_job(
            config=SpreadsheetParsingConfig(
                table_merge_sensitivity=SpreadsheetParsingConfigTableMergeSensitivity.STRONG,
            ),
            file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id}
        if config is not OMIT:
            _request["config"] = config
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/sheets/jobs"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_spreadsheet_job(
        self,
        spreadsheet_job_id: str,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> SpreadsheetJob:
        """
        Get a spreadsheet parsing job.

        When include_results=True (default), the response will include extracted regions and results
        if the job is complete, eliminating the need for a separate /results call.

        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - include_results: typing.Optional[bool].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_spreadsheet_job(
            spreadsheet_job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/sheets/jobs/{spreadsheet_job_id}"
            ),
            params=remove_none_from_dict(
                {"include_results": include_results, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_spreadsheet_job(
        self,
        spreadsheet_job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> typing.Any:
        """
        Delete a spreadsheet parsing job and its associated data.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_spreadsheet_job(
            spreadsheet_job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/sheets/jobs/{spreadsheet_job_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_result_region(
        self,
        spreadsheet_job_id: str,
        region_id: str,
        region_type: SpreadsheetResultType,
        *,
        expires_at_seconds: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> PresignedUrl:
        """
        Generate a presigned URL to download a specific extracted region.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - region_id: str.

            - region_type: SpreadsheetResultType.

            - expires_at_seconds: typing.Optional[int].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import SpreadsheetResultType
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_result_region(
            spreadsheet_job_id="string",
            region_id="string",
            region_type=SpreadsheetResultType.TABLE,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/sheets/jobs/{spreadsheet_job_id}/regions/{region_id}/result/{region_type}",
            ),
            params=remove_none_from_dict(
                {"expires_at_seconds": expires_at_seconds, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_split_jobs(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> SplitJobQueryResponse:
        """
        List document split jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_split_jobs()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/split/jobs"),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SplitJobQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_split_job(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        categories: typing.List[SplitCategory],
        document_input: SplitDocumentInput,
        splitting_strategy: typing.Optional[SplitStrategy] = OMIT,
    ) -> SplitJobResponse:
        """
        Create a document split job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - categories: typing.List[SplitCategory]. Categories to split the document into.

            - document_input: SplitDocumentInput. Document to be split.

            - splitting_strategy: typing.Optional[SplitStrategy]. Strategy for splitting the document.
        ---
        from llama_cloud import SplitDocumentInput, SplitStrategy
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_split_job(
            categories=[],
            document_input=SplitDocumentInput(
                type="string",
                value="string",
            ),
            splitting_strategy=SplitStrategy(),
        )
        """
        _request: typing.Dict[str, typing.Any] = {"categories": categories, "document_input": document_input}
        if splitting_strategy is not OMIT:
            _request["splitting_strategy"] = splitting_strategy
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/split/jobs"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SplitJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_split_job(
        self,
        split_job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> SplitJobResponse:
        """
        Get a document split job.

        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - split_job_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_split_job(
            split_job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/split/jobs/{split_job_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SplitJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_usage_metrics(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        include_total: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        user_id: typing.Optional[str] = None,
        event_types: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        days: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        day_on_or_before: typing.Optional[str] = None,
        day_on_or_after: typing.Optional[str] = None,
        event_aggregation_type: typing.Optional[str] = None,
        event_aggregation_key: typing.Optional[str] = None,
        organization_id: str,
    ) -> UsageMetricQueryResponse:
        """
        List usage metrics with filtering and pagination.

        Parameters:
            - page_size: typing.Optional[int]. Number of items per page

            - page_token: typing.Optional[str]. Token for pagination

            - include_total: typing.Optional[bool]. Include total count in response

            - project_id: typing.Optional[str]. Filter by project ID

            - user_id: typing.Optional[str]. Filter by user ID

            - event_types: typing.Optional[typing.Union[str, typing.List[str]]]. Filter by event types

            - days: typing.Optional[typing.Union[str, typing.List[str]]]. Filter by specific days (YYYY-MM-DD)

            - day_on_or_before: typing.Optional[str]. Filter by days on or before this date (YYYY-MM-DD)

            - day_on_or_after: typing.Optional[str]. Filter by days on or after this date (YYYY-MM-DD)

            - event_aggregation_type: typing.Optional[str]. Filter by event aggregation type

            - event_aggregation_key: typing.Optional[str]. Filter by event aggregation key

            - organization_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_usage_metrics(
            organization_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/usage-metrics"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "include_total": include_total,
                    "project_id": project_id,
                    "user_id": user_id,
                    "event_types": event_types,
                    "days": days,
                    "day_on_or_before": day_on_or_before,
                    "day_on_or_after": day_on_or_after,
                    "event_aggregation_type": event_aggregation_type,
                    "event_aggregation_key": event_aggregation_key,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UsageMetricQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
