# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.jsonable_encoder import jsonable_encoder
from ...core.remove_none_from_dict import remove_none_from_dict
from ...errors.unprocessable_entity_error import UnprocessableEntityError
from ...types.file_count_by_status_response import FileCountByStatusResponse
from ...types.http_validation_error import HttpValidationError
from ...types.managed_ingestion_status_response import ManagedIngestionStatusResponse
from ...types.paginated_list_pipeline_files_response import PaginatedListPipelineFilesResponse
from ...types.pipeline_file import PipelineFile
from ...types.pipeline_file_create import PipelineFileCreate
from .types.pipeline_file_update_custom_metadata_value import PipelineFileUpdateCustomMetadataValue

try:
    import pydantic
    if pydantic.__version__.startswith("1."):
        raise ImportError
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class PipelineFilesClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def add_files_to_pipeline_api(
        self, pipeline_id: str, *, request: typing.List[PipelineFileCreate]
    ) -> typing.List[PipelineFile]:
        """
        Add files to a pipeline.

        Parameters:
            - pipeline_id: str.

            - request: typing.List[PipelineFileCreate].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.pipeline_files.add_files_to_pipeline_api(
            pipeline_id="string",
            request=[],
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[PipelineFile], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_pipeline_file_status_counts(
        self,
        pipeline_id: str,
        *,
        data_source_id: typing.Optional[str] = None,
        only_manually_uploaded: typing.Optional[bool] = None,
    ) -> FileCountByStatusResponse:
        """
        Get files for a pipeline.

        Parameters:
            - pipeline_id: str.

            - data_source_id: typing.Optional[str].

            - only_manually_uploaded: typing.Optional[bool].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.pipeline_files.get_pipeline_file_status_counts(
            pipeline_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files/status-counts"
            ),
            params=remove_none_from_dict(
                {"data_source_id": data_source_id, "only_manually_uploaded": only_manually_uploaded}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileCountByStatusResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_pipeline_file(
        self,
        file_id: str,
        pipeline_id: str,
        *,
        custom_metadata: typing.Optional[
            typing.Dict[str, typing.Optional[PipelineFileUpdateCustomMetadataValue]]
        ] = OMIT,
    ) -> PipelineFile:
        """
        Update a file for a pipeline.

        Parameters:
            - file_id: str.

            - pipeline_id: str.

            - custom_metadata: typing.Optional[typing.Dict[str, typing.Optional[PipelineFileUpdateCustomMetadataValue]]].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.pipeline_files.update_pipeline_file(
            file_id="string",
            pipeline_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if custom_metadata is not OMIT:
            _request["custom_metadata"] = custom_metadata
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files/{file_id}"
            ),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PipelineFile, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_pipeline_file(self, file_id: str, pipeline_id: str) -> None:
        """
        Delete a file from a pipeline.

        Parameters:
            - file_id: str.

            - pipeline_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.pipeline_files.delete_pipeline_file(
            file_id="string",
            pipeline_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files/{file_id}"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_pipeline_file_status(self, file_id: str, pipeline_id: str) -> ManagedIngestionStatusResponse:
        """
        Get status of a file for a pipeline.

        Parameters:
            - file_id: str.

            - pipeline_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.pipeline_files.get_pipeline_file_status(
            file_id="string",
            pipeline_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files/{file_id}/status"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ManagedIngestionStatusResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_pipeline_files_2(
        self,
        pipeline_id: str,
        *,
        data_source_id: typing.Optional[str] = None,
        only_manually_uploaded: typing.Optional[bool] = None,
        file_name_contains: typing.Optional[str] = None,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
        order_by: typing.Optional[str] = None,
    ) -> PaginatedListPipelineFilesResponse:
        """
        Get files for a pipeline.

        Args:
        pipeline_id: ID of the pipeline
        data_source_id: Optional filter by data source ID
        only_manually_uploaded: Filter for only manually uploaded files
        file_name_contains: Optional filter by file name (substring match)
        limit: Limit number of results
        offset: Offset for pagination
        order_by: Field to order by

        Parameters:
            - pipeline_id: str.

            - data_source_id: typing.Optional[str].

            - only_manually_uploaded: typing.Optional[bool].

            - file_name_contains: typing.Optional[str].

            - limit: typing.Optional[int].

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.pipeline_files.list_pipeline_files_2(
            pipeline_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files2"),
            params=remove_none_from_dict(
                {
                    "data_source_id": data_source_id,
                    "only_manually_uploaded": only_manually_uploaded,
                    "file_name_contains": file_name_contains,
                    "limit": limit,
                    "offset": offset,
                    "order_by": order_by,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedListPipelineFilesResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def import_pipeline_metadata(self, pipeline_id: str, *, upload_file: typing.IO) -> typing.Dict[str, str]:
        """
        Import metadata for a pipeline.

        Parameters:
            - pipeline_id: str.

            - upload_file: typing.IO.
        """
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/metadata"),
            data=jsonable_encoder({}),
            files={"upload_file": upload_file},
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Dict[str, str], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_pipeline_files_metadata(self, pipeline_id: str) -> None:
        """
        Delete metadata for all files in a pipeline.

        Parameters:
            - pipeline_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.pipeline_files.delete_pipeline_files_metadata(
            pipeline_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/metadata"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncPipelineFilesClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def add_files_to_pipeline_api(
        self, pipeline_id: str, *, request: typing.List[PipelineFileCreate]
    ) -> typing.List[PipelineFile]:
        """
        Add files to a pipeline.

        Parameters:
            - pipeline_id: str.

            - request: typing.List[PipelineFileCreate].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.pipeline_files.add_files_to_pipeline_api(
            pipeline_id="string",
            request=[],
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[PipelineFile], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_pipeline_file_status_counts(
        self,
        pipeline_id: str,
        *,
        data_source_id: typing.Optional[str] = None,
        only_manually_uploaded: typing.Optional[bool] = None,
    ) -> FileCountByStatusResponse:
        """
        Get files for a pipeline.

        Parameters:
            - pipeline_id: str.

            - data_source_id: typing.Optional[str].

            - only_manually_uploaded: typing.Optional[bool].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.pipeline_files.get_pipeline_file_status_counts(
            pipeline_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files/status-counts"
            ),
            params=remove_none_from_dict(
                {"data_source_id": data_source_id, "only_manually_uploaded": only_manually_uploaded}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileCountByStatusResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_pipeline_file(
        self,
        file_id: str,
        pipeline_id: str,
        *,
        custom_metadata: typing.Optional[
            typing.Dict[str, typing.Optional[PipelineFileUpdateCustomMetadataValue]]
        ] = OMIT,
    ) -> PipelineFile:
        """
        Update a file for a pipeline.

        Parameters:
            - file_id: str.

            - pipeline_id: str.

            - custom_metadata: typing.Optional[typing.Dict[str, typing.Optional[PipelineFileUpdateCustomMetadataValue]]].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.pipeline_files.update_pipeline_file(
            file_id="string",
            pipeline_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if custom_metadata is not OMIT:
            _request["custom_metadata"] = custom_metadata
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files/{file_id}"
            ),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PipelineFile, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_pipeline_file(self, file_id: str, pipeline_id: str) -> None:
        """
        Delete a file from a pipeline.

        Parameters:
            - file_id: str.

            - pipeline_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.pipeline_files.delete_pipeline_file(
            file_id="string",
            pipeline_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files/{file_id}"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_pipeline_file_status(self, file_id: str, pipeline_id: str) -> ManagedIngestionStatusResponse:
        """
        Get status of a file for a pipeline.

        Parameters:
            - file_id: str.

            - pipeline_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.pipeline_files.get_pipeline_file_status(
            file_id="string",
            pipeline_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files/{file_id}/status"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ManagedIngestionStatusResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_pipeline_files_2(
        self,
        pipeline_id: str,
        *,
        data_source_id: typing.Optional[str] = None,
        only_manually_uploaded: typing.Optional[bool] = None,
        file_name_contains: typing.Optional[str] = None,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
        order_by: typing.Optional[str] = None,
    ) -> PaginatedListPipelineFilesResponse:
        """
        Get files for a pipeline.

        Args:
        pipeline_id: ID of the pipeline
        data_source_id: Optional filter by data source ID
        only_manually_uploaded: Filter for only manually uploaded files
        file_name_contains: Optional filter by file name (substring match)
        limit: Limit number of results
        offset: Offset for pagination
        order_by: Field to order by

        Parameters:
            - pipeline_id: str.

            - data_source_id: typing.Optional[str].

            - only_manually_uploaded: typing.Optional[bool].

            - file_name_contains: typing.Optional[str].

            - limit: typing.Optional[int].

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.pipeline_files.list_pipeline_files_2(
            pipeline_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/files2"),
            params=remove_none_from_dict(
                {
                    "data_source_id": data_source_id,
                    "only_manually_uploaded": only_manually_uploaded,
                    "file_name_contains": file_name_contains,
                    "limit": limit,
                    "offset": offset,
                    "order_by": order_by,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedListPipelineFilesResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def import_pipeline_metadata(self, pipeline_id: str, *, upload_file: typing.IO) -> typing.Dict[str, str]:
        """
        Import metadata for a pipeline.

        Parameters:
            - pipeline_id: str.

            - upload_file: typing.IO.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/metadata"),
            data=jsonable_encoder({}),
            files={"upload_file": upload_file},
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Dict[str, str], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_pipeline_files_metadata(self, pipeline_id: str) -> None:
        """
        Delete metadata for all files in a pipeline.

        Parameters:
            - pipeline_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.pipeline_files.delete_pipeline_files_metadata(
            pipeline_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/pipelines/{pipeline_id}/metadata"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
