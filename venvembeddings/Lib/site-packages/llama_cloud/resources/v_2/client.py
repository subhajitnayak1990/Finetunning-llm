# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.jsonable_encoder import jsonable_encoder
from ...core.remove_none_from_dict import remove_none_from_dict
from ...errors.unprocessable_entity_error import UnprocessableEntityError
from ...types.http_validation_error import HttpValidationError
from ...types.llama_parse_agentic_options import LlamaParseAgenticOptions
from ...types.llama_parse_crop_box import LlamaParseCropBox
from ...types.llama_parse_fast_options import LlamaParseFastOptions
from ...types.llama_parse_input_options import LlamaParseInputOptions
from ...types.llama_parse_output_options import LlamaParseOutputOptions
from ...types.llama_parse_page_ranges import LlamaParsePageRanges
from ...types.llama_parse_processing_control import LlamaParseProcessingControl
from ...types.llama_parse_processing_options import LlamaParseProcessingOptions
from ...types.llama_parse_webhook_configuration import LlamaParseWebhookConfiguration
from ...types.parse_job_query_response import ParseJobQueryResponse
from ...types.parse_job_response import ParseJobResponse
from ...types.parse_result_response import ParseResultResponse
from .types.list_parse_jobs_api_v_2_parse_get_request_status import ListParseJobsApiV2ParseGetRequestStatus
from .types.parse_request_configuration_tier import ParseRequestConfigurationTier
from .types.parse_request_configuration_version import ParseRequestConfigurationVersion

try:
    import pydantic
    if pydantic.__version__.startswith("1."):
        raise ImportError
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class V2Client:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list_parse_jobs(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        status: typing.Optional[ListParseJobsApiV2ParseGetRequestStatus] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ParseJobQueryResponse:
        """
        List parse jobs for the current project with optional status filtering and pagination.

        Parameters:
            - page_size: typing.Optional[int]. Number of items per page

            - page_token: typing.Optional[str]. Token for pagination

            - status: typing.Optional[ListParseJobsApiV2ParseGetRequestStatus]. Filter by job status (PENDING, RUNNING, COMPLETED, FAILED, CANCELLED)

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import ListParseJobsApiV2ParseGetRequestStatus
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.v_2.list_parse_jobs(
            status=ListParseJobsApiV2ParseGetRequestStatus.PENDING,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2/parse"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "status": status,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseJobQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def parse_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        agentic_options: typing.Optional[LlamaParseAgenticOptions] = OMIT,
        client_name: typing.Optional[str] = OMIT,
        crop_box: typing.Optional[LlamaParseCropBox] = OMIT,
        disable_cache: typing.Optional[bool] = OMIT,
        fast_options: typing.Optional[LlamaParseFastOptions] = OMIT,
        file_id: typing.Optional[str] = OMIT,
        http_proxy: typing.Optional[str] = OMIT,
        input_options: typing.Optional[LlamaParseInputOptions] = OMIT,
        output_options: typing.Optional[LlamaParseOutputOptions] = OMIT,
        page_ranges: typing.Optional[LlamaParsePageRanges] = OMIT,
        processing_control: typing.Optional[LlamaParseProcessingControl] = OMIT,
        processing_options: typing.Optional[LlamaParseProcessingOptions] = OMIT,
        source_url: typing.Optional[str] = OMIT,
        tier: ParseRequestConfigurationTier,
        version: ParseRequestConfigurationVersion,
        webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]] = OMIT,
    ) -> ParseJobResponse:
        """
        Parse a file by file ID or URL.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - agentic_options: typing.Optional[LlamaParseAgenticOptions].

            - client_name: typing.Optional[str].

            - crop_box: typing.Optional[LlamaParseCropBox]. Document crop box boundaries

            - disable_cache: typing.Optional[bool].

            - fast_options: typing.Optional[LlamaParseFastOptions].

            - file_id: typing.Optional[str].

            - http_proxy: typing.Optional[str].

            - input_options: typing.Optional[LlamaParseInputOptions]. Input format-specific parsing options

            - output_options: typing.Optional[LlamaParseOutputOptions]. Output format and styling options

            - page_ranges: typing.Optional[LlamaParsePageRanges]. Page range selection options

            - processing_control: typing.Optional[LlamaParseProcessingControl]. Job processing control and failure handling

            - processing_options: typing.Optional[LlamaParseProcessingOptions]. Processing options shared across all tiers

            - source_url: typing.Optional[str].

            - tier: ParseRequestConfigurationTier. The parsing tier to use

            - version: ParseRequestConfigurationVersion. Version of the tier configuration

            - webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]]. List of webhook configurations for notifications
        ---
        from llama_cloud import (
            LlamaParseAgenticOptions,
            LlamaParseCropBox,
            LlamaParseFastOptions,
            LlamaParseHtmlOptions,
            LlamaParseIgnoreOptions,
            LlamaParseInputOptions,
            LlamaParseJobFailureConditions,
            LlamaParseMarkdownOptions,
            LlamaParseOcrParameters,
            LlamaParseOutputOptions,
            LlamaParsePageRanges,
            LlamaParsePdfOptions,
            LlamaParsePresentationOptions,
            LlamaParseProcessingControl,
            LlamaParseProcessingOptions,
            LlamaParseProcessingOptionsSpecializedChartParsing,
            LlamaParseSpatialTextOptions,
            LlamaParseSpreadsheetOptions,
            LlamaParseTables,
            LlamaParseTablesAsSpreadsheetOptions,
            LlamaParseTimeouts,
            ParseRequestConfigurationTier,
        )
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.v_2.parse_file(
            agentic_options=LlamaParseAgenticOptions(),
            crop_box=LlamaParseCropBox(),
            fast_options=LlamaParseFastOptions(),
            input_options=LlamaParseInputOptions(
                html=LlamaParseHtmlOptions(),
                pdf=LlamaParsePdfOptions(),
                presentation=LlamaParsePresentationOptions(),
                spreadsheet=LlamaParseSpreadsheetOptions(),
            ),
            output_options=LlamaParseOutputOptions(
                markdown=LlamaParseMarkdownOptions(
                    tables=LlamaParseTables(),
                ),
                spatial_text=LlamaParseSpatialTextOptions(),
                tables_as_spreadsheet=LlamaParseTablesAsSpreadsheetOptions(),
            ),
            page_ranges=LlamaParsePageRanges(),
            processing_control=LlamaParseProcessingControl(
                job_failure_conditions=LlamaParseJobFailureConditions(),
                timeouts=LlamaParseTimeouts(),
            ),
            processing_options=LlamaParseProcessingOptions(
                ignore=LlamaParseIgnoreOptions(),
                ocr_parameters=LlamaParseOcrParameters(),
                specialized_chart_parsing=LlamaParseProcessingOptionsSpecializedChartParsing.AGENTIC_PLUS,
            ),
            tier=ParseRequestConfigurationTier.FAST,
        )
        """
        _request: typing.Dict[str, typing.Any] = {"tier": tier, "version": version}
        if agentic_options is not OMIT:
            _request["agentic_options"] = agentic_options
        if client_name is not OMIT:
            _request["client_name"] = client_name
        if crop_box is not OMIT:
            _request["crop_box"] = crop_box
        if disable_cache is not OMIT:
            _request["disable_cache"] = disable_cache
        if fast_options is not OMIT:
            _request["fast_options"] = fast_options
        if file_id is not OMIT:
            _request["file_id"] = file_id
        if http_proxy is not OMIT:
            _request["http_proxy"] = http_proxy
        if input_options is not OMIT:
            _request["input_options"] = input_options
        if output_options is not OMIT:
            _request["output_options"] = output_options
        if page_ranges is not OMIT:
            _request["page_ranges"] = page_ranges
        if processing_control is not OMIT:
            _request["processing_control"] = processing_control
        if processing_options is not OMIT:
            _request["processing_options"] = processing_options
        if source_url is not OMIT:
            _request["source_url"] = source_url
        if webhook_configurations is not OMIT:
            _request["webhook_configurations"] = webhook_configurations
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2/parse"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upload_file_multipart(
        self, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> ParseJobResponse:
        """
        Upload and parse a file using multipart/form-data.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.v_2.upload_file_multipart()
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2/parse/upload"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_parse_job(
        self,
        job_id: str,
        *,
        expand: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        image_filenames: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ParseResultResponse:
        """
        Retrieve parse job with optional content or metadata.

        Parameters:
            - job_id: str.

            - expand: typing.Optional[typing.Union[str, typing.List[str]]]. Fields to include: text, markdown, items, metadata, text_content_metadata, markdown_content_metadata, items_content_metadata, metadata_content_metadata, xlsx_content_metadata, output_pdf_content_metadata, images_content_metadata. Metadata fields include presigned URLs.

            - image_filenames: typing.Optional[str]. Filter to specific image filenames (optional). Example: image_0.png,image_1.jpg

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.v_2.get_parse_job(
            job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v2/parse/{job_id}"),
            params=remove_none_from_dict(
                {
                    "expand": expand,
                    "image_filenames": image_filenames,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseResultResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncV2Client:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list_parse_jobs(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        status: typing.Optional[ListParseJobsApiV2ParseGetRequestStatus] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ParseJobQueryResponse:
        """
        List parse jobs for the current project with optional status filtering and pagination.

        Parameters:
            - page_size: typing.Optional[int]. Number of items per page

            - page_token: typing.Optional[str]. Token for pagination

            - status: typing.Optional[ListParseJobsApiV2ParseGetRequestStatus]. Filter by job status (PENDING, RUNNING, COMPLETED, FAILED, CANCELLED)

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import ListParseJobsApiV2ParseGetRequestStatus
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.v_2.list_parse_jobs(
            status=ListParseJobsApiV2ParseGetRequestStatus.PENDING,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2/parse"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "status": status,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseJobQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def parse_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        agentic_options: typing.Optional[LlamaParseAgenticOptions] = OMIT,
        client_name: typing.Optional[str] = OMIT,
        crop_box: typing.Optional[LlamaParseCropBox] = OMIT,
        disable_cache: typing.Optional[bool] = OMIT,
        fast_options: typing.Optional[LlamaParseFastOptions] = OMIT,
        file_id: typing.Optional[str] = OMIT,
        http_proxy: typing.Optional[str] = OMIT,
        input_options: typing.Optional[LlamaParseInputOptions] = OMIT,
        output_options: typing.Optional[LlamaParseOutputOptions] = OMIT,
        page_ranges: typing.Optional[LlamaParsePageRanges] = OMIT,
        processing_control: typing.Optional[LlamaParseProcessingControl] = OMIT,
        processing_options: typing.Optional[LlamaParseProcessingOptions] = OMIT,
        source_url: typing.Optional[str] = OMIT,
        tier: ParseRequestConfigurationTier,
        version: ParseRequestConfigurationVersion,
        webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]] = OMIT,
    ) -> ParseJobResponse:
        """
        Parse a file by file ID or URL.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - agentic_options: typing.Optional[LlamaParseAgenticOptions].

            - client_name: typing.Optional[str].

            - crop_box: typing.Optional[LlamaParseCropBox]. Document crop box boundaries

            - disable_cache: typing.Optional[bool].

            - fast_options: typing.Optional[LlamaParseFastOptions].

            - file_id: typing.Optional[str].

            - http_proxy: typing.Optional[str].

            - input_options: typing.Optional[LlamaParseInputOptions]. Input format-specific parsing options

            - output_options: typing.Optional[LlamaParseOutputOptions]. Output format and styling options

            - page_ranges: typing.Optional[LlamaParsePageRanges]. Page range selection options

            - processing_control: typing.Optional[LlamaParseProcessingControl]. Job processing control and failure handling

            - processing_options: typing.Optional[LlamaParseProcessingOptions]. Processing options shared across all tiers

            - source_url: typing.Optional[str].

            - tier: ParseRequestConfigurationTier. The parsing tier to use

            - version: ParseRequestConfigurationVersion. Version of the tier configuration

            - webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]]. List of webhook configurations for notifications
        ---
        from llama_cloud import (
            LlamaParseAgenticOptions,
            LlamaParseCropBox,
            LlamaParseFastOptions,
            LlamaParseHtmlOptions,
            LlamaParseIgnoreOptions,
            LlamaParseInputOptions,
            LlamaParseJobFailureConditions,
            LlamaParseMarkdownOptions,
            LlamaParseOcrParameters,
            LlamaParseOutputOptions,
            LlamaParsePageRanges,
            LlamaParsePdfOptions,
            LlamaParsePresentationOptions,
            LlamaParseProcessingControl,
            LlamaParseProcessingOptions,
            LlamaParseProcessingOptionsSpecializedChartParsing,
            LlamaParseSpatialTextOptions,
            LlamaParseSpreadsheetOptions,
            LlamaParseTables,
            LlamaParseTablesAsSpreadsheetOptions,
            LlamaParseTimeouts,
            ParseRequestConfigurationTier,
        )
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.v_2.parse_file(
            agentic_options=LlamaParseAgenticOptions(),
            crop_box=LlamaParseCropBox(),
            fast_options=LlamaParseFastOptions(),
            input_options=LlamaParseInputOptions(
                html=LlamaParseHtmlOptions(),
                pdf=LlamaParsePdfOptions(),
                presentation=LlamaParsePresentationOptions(),
                spreadsheet=LlamaParseSpreadsheetOptions(),
            ),
            output_options=LlamaParseOutputOptions(
                markdown=LlamaParseMarkdownOptions(
                    tables=LlamaParseTables(),
                ),
                spatial_text=LlamaParseSpatialTextOptions(),
                tables_as_spreadsheet=LlamaParseTablesAsSpreadsheetOptions(),
            ),
            page_ranges=LlamaParsePageRanges(),
            processing_control=LlamaParseProcessingControl(
                job_failure_conditions=LlamaParseJobFailureConditions(),
                timeouts=LlamaParseTimeouts(),
            ),
            processing_options=LlamaParseProcessingOptions(
                ignore=LlamaParseIgnoreOptions(),
                ocr_parameters=LlamaParseOcrParameters(),
                specialized_chart_parsing=LlamaParseProcessingOptionsSpecializedChartParsing.AGENTIC_PLUS,
            ),
            tier=ParseRequestConfigurationTier.FAST,
        )
        """
        _request: typing.Dict[str, typing.Any] = {"tier": tier, "version": version}
        if agentic_options is not OMIT:
            _request["agentic_options"] = agentic_options
        if client_name is not OMIT:
            _request["client_name"] = client_name
        if crop_box is not OMIT:
            _request["crop_box"] = crop_box
        if disable_cache is not OMIT:
            _request["disable_cache"] = disable_cache
        if fast_options is not OMIT:
            _request["fast_options"] = fast_options
        if file_id is not OMIT:
            _request["file_id"] = file_id
        if http_proxy is not OMIT:
            _request["http_proxy"] = http_proxy
        if input_options is not OMIT:
            _request["input_options"] = input_options
        if output_options is not OMIT:
            _request["output_options"] = output_options
        if page_ranges is not OMIT:
            _request["page_ranges"] = page_ranges
        if processing_control is not OMIT:
            _request["processing_control"] = processing_control
        if processing_options is not OMIT:
            _request["processing_options"] = processing_options
        if source_url is not OMIT:
            _request["source_url"] = source_url
        if webhook_configurations is not OMIT:
            _request["webhook_configurations"] = webhook_configurations
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2/parse"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upload_file_multipart(
        self, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> ParseJobResponse:
        """
        Upload and parse a file using multipart/form-data.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.v_2.upload_file_multipart()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2/parse/upload"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_parse_job(
        self,
        job_id: str,
        *,
        expand: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        image_filenames: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ParseResultResponse:
        """
        Retrieve parse job with optional content or metadata.

        Parameters:
            - job_id: str.

            - expand: typing.Optional[typing.Union[str, typing.List[str]]]. Fields to include: text, markdown, items, metadata, text_content_metadata, markdown_content_metadata, items_content_metadata, metadata_content_metadata, xlsx_content_metadata, output_pdf_content_metadata, images_content_metadata. Metadata fields include presigned URLs.

            - image_filenames: typing.Optional[str]. Filter to specific image filenames (optional). Example: image_0.png,image_1.jpg

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.v_2.get_parse_job(
            job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v2/parse/{job_id}"),
            params=remove_none_from_dict(
                {
                    "expand": expand,
                    "image_filenames": image_filenames,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseResultResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
